{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyansh/Documents/Barclays_submission/barclay/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text)\n",
    "    # Remove URLs/links\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove $\n",
    "    text = text.replace('$', '')\n",
    "    # Remove #\n",
    "    text = text.replace('#', '')\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialAspectDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer_name='ProsusAI/finbert', max_length=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file: Path to the CSV file\n",
    "            tokenizer_name: Name of the pretrained tokenizer\n",
    "            max_length: Maximum length of the tokenized sequences\n",
    "        \"\"\"\n",
    "        # Read CSV\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Extract and process aspects\n",
    "        with open(\"unique_aspects\", 'r') as file:\n",
    "            aspects_list = [line.strip() for line in file]\n",
    "\n",
    "        # self.aspects = self.df['aspects'].apply(ast.literal_eval).tolist()\n",
    "        self.aspects = aspects_list #unique aspects\n",
    "\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.aspect_labels = self.mlb.fit_transform(self.aspects)\n",
    "        \n",
    "        # Store aspect classes for reference\n",
    "        self.aspect_classes = self.mlb.classes_\n",
    "        self.num_aspects = len(self.aspect_classes)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def process_aspects(self, aspects):\n",
    "        aspect_names = np.unique(aspects[2:-2].split('/')).tolist()\n",
    "        true_mask = [self.aspects.index(a) for a in aspect_names if a != '']\n",
    "        aspect_ids = [0]*len(self.aspects)\n",
    "        for m in true_mask:\n",
    "            aspect_ids[m] = 1\n",
    "        return aspect_ids\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # print(\"idx: \", idx)\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Get text inputs\n",
    "        sentence = str(row['sentence'])\n",
    "        # print(\"sentence: \", sentence)\n",
    "        snippet = ast.literal_eval(row['snippets'])[0]  # Take first snippet\n",
    "        # print(\"snippet: \", snippet)\n",
    "        target = str(row['target'])\n",
    "        # print(\"target: \", target)\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        sentence_encoding = self.tokenizer(\n",
    "            clean(sentence),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        snippet_encoding = self.tokenizer(\n",
    "            clean(snippet),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        target_encoding = self.tokenizer(\n",
    "            clean(target),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=32,  # Shorter max_length for targets\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Get aspect labels\n",
    "        aspect_label_ids = self.process_aspects(row['aspects'])\n",
    "        \n",
    "        # Remove batch dimension added by tokenizer\n",
    "        return {\n",
    "            'sentence_ids': sentence_encoding['input_ids'].squeeze(0),\n",
    "            'sentence_mask': sentence_encoding['attention_mask'].squeeze(0),\n",
    "            'snippet_ids': snippet_encoding['input_ids'].squeeze(0),\n",
    "            'snippet_mask': snippet_encoding['attention_mask'].squeeze(0),\n",
    "            'target_ids': target_encoding['input_ids'].squeeze(0),\n",
    "            'target_mask': target_encoding['attention_mask'].squeeze(0),\n",
    "            'aspect_label_ids': (torch.tensor(aspect_label_ids, dtype=float)).squeeze(0),\n",
    "            'sentiment_score': torch.FloatTensor([float(row['sentiment_score'])])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "def create_dataloaders(csv_file, batch_size=10, train_split=0.9, seed=42):\n",
    "    \"\"\"\n",
    "    Create train and validation dataloaders\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = FinancialAspectDataset(csv_file)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    \n",
    "    # Split dataset\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, dataset.aspects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader, aspect_classes = create_dataloaders('train.csv', batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetAttention(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        # Reduce number of heads (8 -> 2 or 4)\n",
    "        self.attention = torch.nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=2,  # Reduced from 8\n",
    "            dropout=0.1   # Add dropout for regularization\n",
    "        )\n",
    "        \n",
    "        # Reduce hidden dimension\n",
    "        self.hidden_dim = 768  # Reduced from 768\n",
    "        # self.dim_reducer = torch.nn.Linear(-1, self.hidden_dim) #might be 768 but let's see\n",
    "        \n",
    "    def forward(self, sentence_encoding, snippet_encoding, target_encoding):\n",
    "        # Reduce dimensions\n",
    "        # sentence_reduced = self.dim_reducer(sentence_encoding)\n",
    "        # snippet_reduced = self.dim_reducer(snippet_encoding)\n",
    "        # target_reduced = self.dim_reducer(target_encoding)\n",
    "        \n",
    "        # Apply attention\n",
    "        attn_output, attn_weights = self.attention(\n",
    "            query=target_encoding,\n",
    "            key=sentence_encoding,\n",
    "            value=snippet_encoding\n",
    "        )\n",
    "        \n",
    "        return attn_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspectDetectionModel(torch.nn.Module):\n",
    "    def __init__(self, num_aspects):\n",
    "        super().__init__()\n",
    "        self.finbert = AutoModel.from_pretrained('ProsusAI/finbert')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "        self.label_embedding = self.create_label_embeddings(self.tokenizer, self.finbert).to('cuda:0')\n",
    "        \n",
    "        print(\"label embeddings: \", (self.label_embedding).shape)\n",
    "\n",
    "        #freeze all the layers of bert\n",
    "        for param in self.finbert.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Only fine-tune last few layers\n",
    "        for param in self.finbert.encoder.layer[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self.hidden_dim = 768\n",
    "        # Optimized attention for small data\n",
    "        self.target_attention = TargetAttention(\n",
    "            hidden_dim=768  # Reduced dimension\n",
    "        )\n",
    "        \n",
    "        # Multi-label aspect classifier\n",
    "        # self.aspect_classifier = torch.nn.Sequential(\n",
    "        #     torch.nn.Linear(768, 128),\n",
    "        #     torch.nn.ReLU(),\n",
    "        #     torch.nn.Dropout(0.2),\n",
    "        #     torch.nn.Linear(128, num_aspects),\n",
    "        #     # No sigmoid here - we'll use BCEWithLogitsLoss\n",
    "        # )\n",
    "\n",
    "        self.semantic_matcher = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        )\n",
    "\n",
    "        self.temperature = torch.nn.Parameter(torch.ones(1))\n",
    "        \n",
    "    def forward(self, sentence_ids, sentence_mask, \n",
    "                              snippet_ids, snippet_mask,\n",
    "                              target_ids, target_mask):\n",
    "        # Encode inputs\n",
    "        sentence_encoding = self.finbert(sentence_ids, sentence_mask)[0]  # [batch_size, seq_len, 768]\n",
    "        sentence_encoding = sentence_encoding[:, 0, :] # B, H\n",
    "        # print(\"sent_encoding: \",sentence_encoding.shape)\n",
    "        snippet_encoding = self.finbert(snippet_ids, snippet_mask)[0]\n",
    "        snippet_encoding = snippet_encoding[:, 0, :]\n",
    "        # print(\"snippet_encoding: \",snippet_encoding.shape)\n",
    "        target_encoding = self.finbert(target_ids, target_mask)[0]\n",
    "        target_encoding = target_encoding[:,0,:]\n",
    "        # print(\"target_encoding: \",target_encoding.shape)\n",
    "        \n",
    "        # Get target-aware representation\n",
    "        target_aware_output, _ = self.target_attention(\n",
    "            sentence_encoding=sentence_encoding,\n",
    "            snippet_encoding=snippet_encoding,\n",
    "            target_encoding=target_encoding\n",
    "        ) # (B, H)\n",
    "\n",
    "        # print(\"attn_output: \",target_aware_output.shape)\n",
    "        \n",
    "        # Predict aspects\n",
    "        # aspect_logits = self.aspect_classifier(target_aware_output)\n",
    "        # print(\"output_logits: \",aspect_logits.shape)\n",
    "        # print(aspect_logits[0])\n",
    "        # return aspect_logits\n",
    "\n",
    "        text_repr= self.semantic_matcher(target_aware_output)\n",
    "        similarities = self.calculate_similarities(text_repr)\n",
    "\n",
    "        # print(\"similarities: \", similarities.shape)\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def calculate_similarities(self, text_repr):\n",
    "        # Normalize embeddings\n",
    "        text_repr = torch.nn.functional.normalize(text_repr, dim=-1)\n",
    "        label_embeddings = torch.nn.functional.normalize(self.label_embedding, dim=-1)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarities = torch.matmul(text_repr, label_embeddings.T)\n",
    "        \n",
    "        # Scale with learnable temperature\n",
    "        similarities = similarities * self.temperature\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def create_label_embeddings(self, tokenizer, finbert):\n",
    "        \"\"\"Create embeddings for all labels using FinBERT\"\"\"\n",
    "        labels = None\n",
    "        with open(\"unique_aspects\", 'r') as file:\n",
    "            labels = [line.strip() for line in file]\n",
    "\n",
    "        label_embeddings = {}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for label in labels:\n",
    "                # Tokenize label\n",
    "                inputs = tokenizer(\n",
    "                    label,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Get embedding from FinBERT\n",
    "                outputs = finbert(**inputs)\n",
    "                # Use [CLS] token embedding\n",
    "                label_emb = outputs.last_hidden_state[:, 0, :]  # [1, hidden_dim]\n",
    "                label_embeddings[label] = label_emb\n",
    "                \n",
    "        # Stack all label embeddings\n",
    "        return torch.cat(list(label_embeddings.values()), dim=0)  # [num_labels, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASPECT_LIST = 119\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label embeddings:  torch.Size([119, 768])\n"
     ]
    }
   ],
   "source": [
    "model = AspectDetectionModel(num_aspects=ASPECT_LIST).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()  # Better than BCE for numerical stability\n",
    "\n",
    "# Use different learning rates for BERT and custom layers\n",
    "optimizer = AdamW([\n",
    "    {'params': model.finbert.parameters(), 'lr': 1e-3},\n",
    "    {'params': model.target_attention.parameters(), 'lr': 1e-3},\n",
    "    {'params': model.semantic_matcher.parameters(), 'lr': 1e-2},\n",
    "    {'params': model.temperature, 'lr': 1e-2}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.13394873701975124\n",
      "loss:  0.13696777626496404\n",
      "loss:  0.1417593694910282\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Get batch data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sentence_ids \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m sentence_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m snippet_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnippet_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    cnt = 0\n",
    "    for batch in train_loader:\n",
    "        cnt += 1\n",
    "        # Get batch data\n",
    "        sentence_ids = batch['sentence_ids'].to(device)\n",
    "        sentence_mask = batch['sentence_mask'].to(device)\n",
    "        snippet_ids = batch['snippet_ids'].to(device)\n",
    "        snippet_mask = batch['snippet_mask'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "        target_mask = batch['target_mask'].to(device)\n",
    "\n",
    "        aspect_labels = batch['aspect_label_ids'].to(device)  # Binary matrix [batch_size, num_aspects]\n",
    "        # print(\"true: \", aspect_labels.shape)\n",
    "        \n",
    "        # print(\"forward pass: \")\n",
    "        # Forward pass\n",
    "        similarity_logits = model(sentence_ids, sentence_mask, \n",
    "                              snippet_ids, snippet_mask,\n",
    "                              target_ids, target_mask)\n",
    "        \n",
    "        # print(\"pred: \", aspect_logits.shape)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(similarity_logits, aspect_labels)\n",
    "\n",
    "        if cnt%10==0:\n",
    "            print(\"loss: \", loss.item())\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"epoch_loss: \", (epoch_loss/cnt).item())\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_steps = 0\n",
    "        \n",
    "    print(\"\\nRunning Validation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move batch to device\n",
    "            sentence_ids = batch['sentence_ids'].to(device)\n",
    "            sentence_mask = batch['sentence_mask'].to(device)\n",
    "            snippet_ids = batch['snippet_ids'].to(device)\n",
    "            snippet_mask = batch['snippet_mask'].to(device)\n",
    "            target_ids = batch['target_ids'].to(device)\n",
    "            target_mask = batch['target_mask'].to(device)\n",
    "\n",
    "            aspect_labels = batch['aspect_label_ids'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            aspect_logits = model(sentence_ids, sentence_mask, \n",
    "                              snippet_ids, snippet_mask,\n",
    "                              target_ids, target_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(aspect_logits, aspect_labels)\n",
    "            total_val_loss += loss.item()\n",
    "            val_steps += 1\n",
    "    \n",
    "    avg_val_loss = total_val_loss / val_steps\n",
    "    print(\"val loss: \", avg_val_loss, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader, _ , _ = create_dataloaders('validation.csv', batch_size=16, train_split=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Validation...\n",
      "Validation Loss: 0.1452\n",
      "\n",
      "Micro-averaged metrics:\n",
      "Precision: 0.0229\n",
      "Recall: 0.1133\n",
      "F1-score: 0.0381\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_val_loss = 0\n",
    "val_steps = 0\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "    \n",
    "print(\"\\nRunning Validation...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        # Move batch to device\n",
    "        sentence_ids = batch['sentence_ids'].to(device)\n",
    "        sentence_mask = batch['sentence_mask'].to(device)\n",
    "        snippet_ids = batch['snippet_ids'].to(device)\n",
    "        snippet_mask = batch['snippet_mask'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "        target_mask = batch['target_mask'].to(device)\n",
    "        aspect_labels = batch['aspect_label_ids'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        aspect_logits = model(sentence_ids, sentence_mask, \n",
    "                          snippet_ids, snippet_mask,\n",
    "                          target_ids, target_mask)\n",
    "        \n",
    "        # print(aspect_logits[0])\n",
    "        # print(aspect_labels[0])\n",
    "        # break\n",
    "        # Calculate loss\n",
    "        loss = criterion(aspect_logits, aspect_labels)\n",
    "        total_val_loss += loss.item()\n",
    "        val_steps += 1\n",
    "        \n",
    "        # Convert logits to predictions\n",
    "        predictions = torch.sigmoid(aspect_logits) > 0.1  # threshold at 0.5\n",
    "        \n",
    "        # Convert to numpy for sklearn metrics\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        true_labels = aspect_labels.cpu().numpy()\n",
    "\n",
    "        # print(np.unique(predictions, return_counts=True))\n",
    "        # print(np.unique(true_labels, return_counts=True))\n",
    "        # print(predictions)\n",
    "        # break\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_true_labels.append(true_labels)\n",
    "\n",
    "# Concatenate all batches\n",
    "all_predictions = np.vstack(all_predictions)\n",
    "all_true_labels = np.vstack(all_true_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "# micro average\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "    all_true_labels, all_predictions, average='micro'\n",
    ")\n",
    "avg_val_loss = total_val_loss / val_steps\n",
    "\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(\"\\nMicro-averaged metrics:\")\n",
    "print(f\"Precision: {precision_micro:.4f}\")\n",
    "print(f\"Recall: {recall_micro:.4f}\")\n",
    "print(f\"F1-score: {f1_micro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5918, -1.8610, -2.5541, -2.4071])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([-2.5918, -1.8610, -2.5541, -2.4071])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0697, 0.1346, 0.0722, 0.0826])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barclay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
